{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here is a tool for nonlinear approximation of the retention rate using a model containing 3 elements: the main trend function, offsets for patches and weekly seasonality.\n",
        "\n",
        "Run the first notebook's block, then run the second block and use the UI to fill in the settings.\n",
        "\n",
        "Finally, run the second block to start the learning process and display the results.\n",
        "\n",
        "Dmitry Baltin, 2023,\n",
        "\n",
        "https://github.com/dmitrybaltin/retention-rate-approximator"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2LdXLr8G2sPy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "#@title Import libraries, define classes and functions\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ConstantFunction(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        super(ConstantFunction, self).__init__()\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor([initial_weights]))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.25]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret_value = torch.ones_like(x)*self.w[0]\n",
        "        return ret_value\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0]\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):\n",
        "        new_w = torch.mean(y_train).unsqueeze(0)\n",
        "        self.w = nn.Parameter(new_w)\n",
        "\n",
        "class LinearFunction(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        super(LinearFunction, self).__init__()\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.25, 0.25]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.w[1] + self.w[0]\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0, 0]\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):\n",
        "        firstValue = y_train[torch.argmin(x_train)]\n",
        "        lastValue =  y_train[torch.argmax(x_train)]\n",
        "\n",
        "        new_w = [lastValue, firstValue - lastValue]\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "# Approximation of a decreasing process by a linear-fractional function\n",
        "class InverseFunction(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        super(InverseFunction, self).__init__()\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.25, 0.25, 1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w[0] + torch.ones_like(x) * self.w[1] / (x + self.w[2])\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0, 0, 10]  # The value 10 was obtained by experience\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):  # The value 1 was obtained by experience\n",
        "\n",
        "        firstValue = y_train[torch.argmin(x_train)]\n",
        "        lastValue =  y_train[torch.argmax(x_train)]\n",
        "\n",
        "        new_w = [lastValue, firstValue - lastValue, 1.0]\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "class InverseFunction_4w(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        super(InverseFunction_4w, self).__init__()\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.25, 0.25, 1, 1]))\n",
        "\n",
        "        # todo: !!!! add constrains. all the weights must be > 0\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.w[0] + torch.ones_like(x) * self.w[1] / (torch.pow(x, self.w[3]) + self.w[2])\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0, 0, 10, 1]  # The value 10 was obtained by experience\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):  # The value 1 was obtained by experience\n",
        "\n",
        "        firstValue = y_train[torch.argmin(x_train)]\n",
        "        lastValue =  y_train[torch.argmax(x_train)]\n",
        "\n",
        "        new_w = [lastValue, firstValue - lastValue, 1.0, 1.0]\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "class LinearFractionalFunction_new(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        super(LinearFractionalFunction_new, self).__init__()\n",
        "\n",
        "        #print('LinearFractionalDecreaser3w_v2 weights = {0}'.format(initial_weights))\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w0 = nn.Parameter(torch.Tensor([initial_weights[0]]))\n",
        "            self.w1 = nn.Parameter(torch.Tensor([initial_weights[1]]))\n",
        "            self.w2 = nn.Parameter(torch.Tensor([initial_weights[2]]))\n",
        "        else:\n",
        "            self.w0 = nn.Parameter(torch.Tensor([0.5]))\n",
        "            self.w1 = nn.Parameter(torch.Tensor([0.25]))\n",
        "            self.w2 = nn.Parameter(torch.Tensor([0.1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return (x / (x + 1/self.w2[0])) * (self.w1[0] - self.w0[0]) + self.w0[0]\n",
        "        #return self.w[0] - (x / (x + torch.pow(self.w[2],2))) * self.w[1]\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            self.w0 = nn.Parameter(torch.Tensor([0.5]))\n",
        "            self.w1 = nn.Parameter(torch.Tensor([0.25]))\n",
        "            self.w2 = nn.Parameter(torch.Tensor([0.1]))\n",
        "        else:\n",
        "            self.w0 = nn.Parameter(torch.Tensor([new_w[0]]))\n",
        "            self.w1 = nn.Parameter(torch.Tensor([new_w[1]]))\n",
        "            self.w2 = nn.Parameter(torch.Tensor([new_w[2]]))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):  # The value 10 was obtained by experience\n",
        "\n",
        "        firstValue = torch.max(y_train)\n",
        "        lastValue =  torch.min(y_train)\n",
        "        w0 = firstValue\n",
        "        w1 = firstValue - lastValue\n",
        "\n",
        "        if w0 < 0:\n",
        "            w0 = 0.1\n",
        "        if w1 < 0:\n",
        "            w1 = 0\n",
        "        if w1 > w0:\n",
        "            w1 = w0\n",
        "\n",
        "        x_mean = torch.mean(x_train)\n",
        "        y_mean = torch.mean(y_train)\n",
        "\n",
        "        if x_mean != 0:\n",
        "            w2 = ( w1 / (w0 - y_mean) - 1 ) / x_mean\n",
        "        else:\n",
        "            w2 = 0.05\n",
        "\n",
        "        self.reset_weights([w0, w1, w2])\n",
        "\n",
        "class LinearFractionalFunction(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        #super(LinearFractionalFunction, self).__init__()\n",
        "        super().__init__()\n",
        "\n",
        "        #print('LinearFractionalDecreaser3w_v2 weights = {0}'.format(initial_weights))\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.5, 0.25, 20]))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return (x / (x + self.w[2])) * (-self.w[1]) + self.w[0]\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0, 0, 10]  # The value 10 was obtained by experience\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):  # The value 10 was obtained by experience\n",
        "\n",
        "        firstValue = torch.max(y_train)\n",
        "        lastValue =  torch.min(y_train)\n",
        "        w0 = firstValue\n",
        "        w1 = firstValue - lastValue\n",
        "\n",
        "        if w0 < 0:\n",
        "            w0 = 0.1\n",
        "        if w1 < 0:\n",
        "            w1 = 0\n",
        "        if w1 > w0:\n",
        "            w1 = w0\n",
        "\n",
        "        x_mean = torch.mean(x_train)\n",
        "        y_mean = torch.mean(y_train)\n",
        "\n",
        "        if y_mean - w0 != 0:\n",
        "            w2 = x_mean * ( w1 / (w0 - y_mean) - 1 )\n",
        "        else:\n",
        "            w2 = 20\n",
        "\n",
        "        self.reset_weights([w0, w1, w2])\n",
        "\n",
        "class SigmaFunction(torch.nn.Module):\n",
        "    def __init__(self, initial_weights=None):\n",
        "\n",
        "        #super(LinearFractionalFunction, self).__init__()\n",
        "        super().__init__()\n",
        "\n",
        "        #print('LinearFractionalDecreaser3w_v2 weights = {0}'.format(initial_weights))\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.Tensor([0.5, 0.25, 20]))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return torch.nn.Sigmoid()(-x*self.w[2]*2) * self.w[1] + self.w[0]\n",
        "\n",
        "    def reset_weights(self, new_w=None):\n",
        "        if new_w is None:\n",
        "            new_w = [0, 0, 10]  # The value 10 was obtained by experience\n",
        "        self.w = nn.Parameter(torch.Tensor(new_w))\n",
        "\n",
        "    # Initialize weights using train dataset\n",
        "    def init_weights_from_train_data(self, x_train, y_train):  # The value 10 was obtained by experience\n",
        "\n",
        "        firstValue = torch.max(y_train)\n",
        "        lastValue =  torch.min(y_train)\n",
        "        w0 = firstValue\n",
        "        w1 = firstValue - lastValue\n",
        "\n",
        "        x_mean = torch.mean(x_train)\n",
        "        y_mean = torch.mean(y_train)\n",
        "\n",
        "        if x_mean != 0:\n",
        "            w2 = ( w1 / (w0 - y_mean) - 1 ) / x_mean\n",
        "        else:\n",
        "            w2 = 0.05\n",
        "\n",
        "        self.reset_weights([w0, w1, w2])\n",
        "\n",
        "# Approximation of weekly fluctuations. Every day of week has its own constant weight\n",
        "class WeekFunction(torch.nn.Module):\n",
        "    def __init__(self, first_day_of_week:int, regularizer_base:int, initial_weights=None):\n",
        "        super(WeekFunction, self).__init__()\n",
        "\n",
        "        self.first_day_of_week = first_day_of_week\n",
        "\n",
        "        if initial_weights is not None:\n",
        "            self.w = nn.Parameter(torch.Tensor(initial_weights))\n",
        "        else:\n",
        "            self.w = nn.Parameter(torch.ones(7))\n",
        "\n",
        "        self.regularizer_base = regularizer_base\n",
        "\n",
        "    def forward(self, day_numbers):\n",
        "        day_of_week = (day_numbers.type(torch.long) + 7 - self.first_day_of_week) % 7\n",
        "        weight_values = self.w[day_of_week]\n",
        "        return weight_values\n",
        "\n",
        "    def regularize(self):\n",
        "        return torch.square(torch.mean(self.w) - self.regularizer_base)\n",
        "\n",
        "\n",
        "def multiply_connector(input1, input2):\n",
        "    return torch.mul(input1, input2)\n",
        "\n",
        "def additive_connector(input1, input2):\n",
        "    return torch.add(input1, input2)\n",
        "\n",
        "\n",
        "class ApproximatorsFactory():\n",
        "\n",
        "    main_functions = [\n",
        "        ['w0', ConstantFunction, [0.25]],\n",
        "        ['w0+w1*x', LinearFunction, [0.25, 0]],\n",
        "        ['w0+w1/(w2+x)', InverseFunction, [0.25, 0.25, 1.0]],\n",
        "        ['w0-w1*x/(w2+x)', LinearFractionalFunction, [0.5, 0.25, 10.0]],\n",
        "        ['w0-(w0-w1)*x/(1/w2+x)', LinearFractionalFunction_new, [0.5, 0.25, 0.1]],\n",
        "        ['w0+w1/(w2+pow(x,w3))', InverseFunction_4w, [0.25, 0.25, 1.0, 1]],\n",
        "        ['w0+w1*Sigmoid(x*w3)', SigmaFunction, [0.5, 0.25, 0.05]]]\n",
        "\n",
        "    chain_functions = [\n",
        "        ['w0', ConstantFunction, [0.25]],\n",
        "        ['w0+w1*x', LinearFunction, [0.25, 0]]]\n",
        "\n",
        "    connectors = [\n",
        "        ['mul', multiply_connector,   1],\n",
        "        ['add', additive_connector,   0]]\n",
        "\n",
        "    @staticmethod\n",
        "    def create_main_function(function_type, initial_weights):\n",
        "\n",
        "        if function_type is None:\n",
        "            return ApproximatorsFactory.main_functions[0][1](initial_weights)\n",
        "\n",
        "        for index, row in enumerate(ApproximatorsFactory.main_functions):\n",
        "            if function_type == index or function_type == str(index) or function_type == row[0]:\n",
        "                return row[1](initial_weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_chain_function(function_type, initial_weights):\n",
        "\n",
        "        if function_type is None:\n",
        "            return ApproximatorsFactory.chain_functions[0][1](initial_weights)\n",
        "\n",
        "        for index, row in enumerate(ApproximatorsFactory.chain_functions):\n",
        "            if function_type == index or function_type == str(index) or function_type == row[0]:\n",
        "                return row[1](initial_weights)\n",
        "\n",
        "        return ApproximatorsFactory.chain_functions[0][1](initial_weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_connector(connector_type):\n",
        "\n",
        "        if connector_type is None:\n",
        "            row = ApproximatorsFactory.connectors[0]\n",
        "            return  row[1], row[2]\n",
        "\n",
        "        for index, row in enumerate(ApproximatorsFactory.connectors):\n",
        "            if connector_type == index or connector_type == str(index) or connector_type == row[0]:\n",
        "                return row[1], row[2]\n",
        "\n",
        "        row = ApproximatorsFactory.connectors[0]\n",
        "        return  row[1], row[2]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_main_function_weights_number(function_type):\n",
        "        if function_type is None:\n",
        "            return None\n",
        "\n",
        "        for index, row in enumerate(ApproximatorsFactory.main_functions):\n",
        "            if function_type == index or function_type == str(index) or function_type == row[0]:\n",
        "                return row[2]\n",
        "\n",
        "        return None\n",
        "\n",
        "class ComplexApproximator(nn.Module):\n",
        "\n",
        "    def __init_main_function(self,\n",
        "                            main_function_type='0',\n",
        "                            main_function_weights=None):\n",
        "\n",
        "        self.main_function = ApproximatorsFactory.create_main_function(main_function_type, main_function_weights)\n",
        "\n",
        "    def __init_chains_functions(self,\n",
        "                                patches_dates=None,\n",
        "                                chain_functions_type='0',\n",
        "                                chain_functions_weights=None):\n",
        "\n",
        "        # Create sorted list of all the patches\n",
        "        if patches_dates is not None:\n",
        "            # Create array of patches removing incorrect numbers\n",
        "            self.patches_dates = [patch_date for patch_date in patches_dates if patch_date > 0]\n",
        "            self.patches_dates = list(set(self.patches_dates))\n",
        "        else:\n",
        "            self.patches_dates = []\n",
        "        self.patches_dates.sort()\n",
        "\n",
        "        chain_functions = []\n",
        "        for i in range(0, len(self.patches_dates)):\n",
        "            if chain_functions_weights is not None and i < len(chain_functions_weights):\n",
        "                initial_weights = chain_functions_weights[i]\n",
        "            else:\n",
        "                initial_weights = None\n",
        "\n",
        "            new_function = ApproximatorsFactory.create_chain_function(chain_functions_type, initial_weights)\n",
        "\n",
        "            chain_functions.append(new_function)\n",
        "\n",
        "        self.chain_functions = nn.ModuleList(chain_functions)\n",
        "\n",
        "    def __init_week_function(self,\n",
        "                             first_day_of_week,\n",
        "                             regularizer_base,\n",
        "                             week_function_initial_weights=None):\n",
        "\n",
        "        self.week_function = WeekFunction(first_day_of_week, regularizer_base, week_function_initial_weights)\n",
        "\n",
        "    def __init_connector(self, connector_type):\n",
        "        self.connector, regularizer_base = ApproximatorsFactory.create_connector(connector_type)\n",
        "        return  regularizer_base\n",
        "\n",
        "    def __init__(self,\n",
        "                 first_day_of_week: int,\n",
        "                 patches_dates=None,\n",
        "                 main_function_type=0,\n",
        "                 chain_functions_type=0,\n",
        "                 connector_type='mul',\n",
        "                 main_function_initial_weights=None,\n",
        "                 chain_functions_initial_weights=None,\n",
        "                 week_function_initial_weights=None):\n",
        "\n",
        "        super(ComplexApproximator, self).__init__()\n",
        "\n",
        "        self.__init_main_function(main_function_type,\n",
        "                                  main_function_initial_weights)\n",
        "        self.__init_chains_functions(patches_dates,\n",
        "                                     chain_functions_type,\n",
        "                                     chain_functions_initial_weights)\n",
        "        regularizer_base = self.__init_connector(connector_type)\n",
        "        self.__init_week_function(first_day_of_week, regularizer_base, week_function_initial_weights)\n",
        "\n",
        "    def init_weights_from_train_data(self, x_initial, y_initial):\n",
        "\n",
        "        self.main_function.init_weights_from_train_data(x_initial, y_initial)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.connector(self.forward_trend_function(x), self.forward_week_function(x))\n",
        "\n",
        "    def forward_trend_function(self, x):\n",
        "\n",
        "        result = self.main_function.forward(x)\n",
        "\n",
        "        if len(self.patches_dates)>0:\n",
        "            chain_mask = (x >= self.patches_dates[-1])\n",
        "            val = self.chain_functions[-1](x[chain_mask])\n",
        "            result[chain_mask] += val\n",
        "\n",
        "            for i in range(len(self.chain_functions) - 2, -1, -1):\n",
        "                chain_mask = (x >= self.patches_dates[i]) * (x < self.patches_dates[i+1])\n",
        "                val = self.chain_functions[i](x[chain_mask])\n",
        "                result[chain_mask] += val\n",
        "\n",
        "        return result\n",
        "\n",
        "    def forward_week_function(self, x):\n",
        "        return self.week_function(x)\n",
        "\n",
        "    def regularize(self):\n",
        "        return self.week_function.regularize()\n",
        "\n",
        "    def print_summary(self, print_function_types=False):\n",
        "        if print_function_types:\n",
        "            print('Main function = ', self.main_function)\n",
        "            print('Chain functions = ', self.chain_functions)\n",
        "            print('Week function = ', self.week_function)\n",
        "\n",
        "        for name, param in self.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(name, param.data)\n",
        "\n",
        "\n",
        "def separate_dataset_by_indices(indices_list_2d, data):\n",
        "    data_by_patches = []\n",
        "    for i in indices_list_2d:\n",
        "        data_by_patches.append(data[i])\n",
        "\n",
        "    return data_by_patches\n",
        "\n",
        "# Separate x_train ans y_train by patches\n",
        "# return two lists of lists\n",
        "def indices_of_x_by_patches(x_data, patches_dates):\n",
        "\n",
        "    indices = []\n",
        "    # Append all the patches excluding the last\n",
        "    for patch_index in range(1, len(patches_dates)):\n",
        "        indices.append([])\n",
        "\n",
        "        start_date = patches_dates[patch_index - 1]\n",
        "        end_date = patches_dates[patch_index]\n",
        "\n",
        "        for index in range(len(x_data)):\n",
        "            x = x_data[index].tolist()\n",
        "            if x >= start_date and x < end_date:\n",
        "                indices[-1].append(index)\n",
        "\n",
        "    # Append last patch\n",
        "    indices.append([])\n",
        "    for index in range(len(x_data)):\n",
        "        x = x_data[index].tolist()\n",
        "        if x >= patches_dates[-1]:\n",
        "            indices[-1].append(index)\n",
        "\n",
        "    return indices, separate_dataset_by_indices(indices, x_data)\n",
        "\n",
        "# Custom mse loss function with use the size of sample in every point to estimate relative variation\n",
        "# of normal distribution in this point\n",
        "# The sample size is obtained from the 0 element of y_true\n",
        "# It is not required to change the model to use this function. But you need to add sample size to x_true argument\n",
        "# as zero element when you call model.fit function\n",
        "def custom_mse_loss(y_pred,\n",
        "                    y_true,\n",
        "                    sample_size_true,\n",
        "                    regularizer,\n",
        "                    regualizer_lambda):\n",
        "\n",
        "    #temp = torch.square(y_pred - y_true) * sample_size_true / (-y_true * (y_true - 1)) / torch.sum(sample_size_true)\n",
        "    temp = torch.square(y_pred - y_true) * sample_size_true / (-y_pred * (y_pred - 1)) / torch.sum(sample_size_true)\n",
        "\n",
        "    return torch.mean(temp) + regularizer() * regualizer_lambda\n",
        "\n",
        "def save_retention_data_to_local_csv(days,\n",
        "                        installs,\n",
        "                        retention,\n",
        "                        retention_mean = None,\n",
        "                        date_of_release = None):\n",
        "\n",
        "    print('date_of_release = ', date_of_release)\n",
        "\n",
        "    if retention_mean is None:\n",
        "        retention_mean = torch.zeros_like(installs)\n",
        "\n",
        "    if date_of_release==None:\n",
        "        table = torch.stack((days, installs, retention, retention_mean), 1).detach().numpy()\n",
        "        df = pd.DataFrame(table)\n",
        "        df.columns = ['date', 'installs', 'retention', 'retention_mean']\n",
        "    else:\n",
        "        date_list = [date_of_release + datetime.timedelta(days=day) for day in days.tolist()]\n",
        "        date_series = pd.Series(date_list, name='date')\n",
        "\n",
        "        table = torch.stack((installs, retention, retention_mean), 1).detach().numpy()\n",
        "        df = pd.DataFrame(table)\n",
        "        df.columns = ['installs', 'retention', 'retention_mean']\n",
        "\n",
        "        df = pd.concat([date_series, df], axis=1)\n",
        "\n",
        "    filename = 'exoprt.csv'\n",
        "    df.to_csv(filename, index=False)\n",
        "    files.download(filename)\n",
        "\n",
        "    return filename\n",
        "\n",
        "def load_retention_from_local_csv(file):\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        dates_list = df['date'].tolist()\n",
        "        first_date = min(dates_list)\n",
        "        days = [(date_ - first_date).days for date_ in dates_list]\n",
        "\n",
        "        date = torch.clamp(torch.tensor(days), 0, 100000000000000).float()\n",
        "        installs = torch.clamp(torch.tensor(df['installs'].values), 1, 10000000000)\n",
        "        retention = torch.clamp(torch.tensor(df['retention'].values), 0,1)\n",
        "        retention_mean = torch.clamp(torch.tensor(df['retention_mean'].values), 0,1)\n",
        "\n",
        "        return date, installs, retention, retention_mean, first_date, df\n",
        "\n",
        "    except ValueError:\n",
        "        print('Error! Wrong file format')\n",
        "        return None, None, None, None, None\n",
        "\n",
        "\n",
        "#Tools functions for evaluating confidence interval of approximation\n",
        "def separate_intervals(x_tensor, y_tensor, x_intervals_by_start):\n",
        "    x_sets = []\n",
        "    y_sets = []\n",
        "    x_intervals_by_start = [0.0] + x_intervals_by_start + [float('inf')]  # add start and end intervals\n",
        "    for i in range(len(x_intervals_by_start)-1):\n",
        "        start = x_intervals_by_start[i]\n",
        "        end = x_intervals_by_start[i+1]\n",
        "        mask = (x_tensor >= start) & (x_tensor < end)  # boolean mask for selecting indices\n",
        "        x_sets.append(x_tensor[mask])\n",
        "        y_sets.append(y_tensor[mask])\n",
        "    return x_sets, y_sets\n",
        "\n",
        "def extract_avg_values_of_patches(x_tensor, x_intervals_by_start, y_tensor_by_intervals):\n",
        "\n",
        "    y_tensor_estimated = []\n",
        "    x_intervals_by_start = [0.0] + x_intervals_by_start + [float('inf')]  # add start and end intervals\n",
        "    for i in range(len(x_intervals_by_start)-1):\n",
        "        start = x_intervals_by_start[i]\n",
        "        end = x_intervals_by_start[i+1]\n",
        "        elements = torch.sum((x_tensor >= start) & (x_tensor < end)).item()  # boolean mask for selecting indices\n",
        "\n",
        "        y_tensor_estimated.append(torch.ones(int(elements)) * y_tensor_by_intervals[i])\n",
        "\n",
        "    return torch.cat(y_tensor_estimated)\n",
        "\n",
        "def evaluate_ideal_confidence_interval(_dates,\n",
        "                                       _retention,\n",
        "                                       _installs,\n",
        "                                       _patches_dates,\n",
        "                                       sigmas_number,\n",
        "                                       _dates_for_plotting,\n",
        "                                       _retention_for_plotting):\n",
        "\n",
        "    _dates = _dates.to(device='cpu')\n",
        "    _retention = _retention.to(device='cpu')\n",
        "\n",
        "    dates_per_patches, retention_per_patches = separate_intervals(_dates, _retention, _patches_dates)\n",
        "    _, installs_per_patch = separate_intervals(_dates, _installs, _patches_dates)\n",
        "    overal_inst_per_patches = [torch.sum(inst) for inst in installs_per_patch]\n",
        "    avg_retention_per_patches = torch.stack([(torch.sum(ret_per_patch*ins)/torch.sum(ins)) for (ret_per_patch, ins) in list(zip(retention_per_patches, dates_per_patches))])\n",
        "    sigma_per_patch = torch.stack([torch.sqrt(-p*(p-1)/N) for p, N in list(zip(avg_retention_per_patches, overal_inst_per_patches))]).to(device='cpu')\n",
        "\n",
        "    estimated_sigma = extract_avg_values_of_patches(_dates_for_plotting, _patches_dates, sigma_per_patch)\n",
        "    return _retention_for_plotting - estimated_sigma * sigmas_number, _retention_for_plotting + estimated_sigma * sigmas_number,\n",
        "\n",
        "#Generate an example of dataset\n",
        "def generate_retention_dataset_2(total_days,\n",
        "                                 first_day_of_week,\n",
        "                                 patches_dates,\n",
        "                                 main_function_type,\n",
        "                                 chains_functions_type,\n",
        "                                 main_function_weights,\n",
        "                                 chains_functions_weights,\n",
        "                                 week_function_weights,\n",
        "                                 daily_installs_mean,\n",
        "                                 daily_installs_sigma):\n",
        "\n",
        "    x = torch.FloatTensor(list(range(total_days)))\n",
        "\n",
        "    #todo: Add random to all the parameters\n",
        "\n",
        "    model = ComplexApproximator(first_day_of_week,\n",
        "                                patches_dates=patches_dates,\n",
        "                                main_function_type=main_function_type,\n",
        "                                chain_functions_type=chains_functions_type,\n",
        "                                main_function_initial_weights=main_function_weights,\n",
        "                                chain_functions_initial_weights=chains_functions_weights)\n",
        "\n",
        "    y_modeled_trend = model.forward(x)\n",
        "\n",
        "    model = ComplexApproximator(first_day_of_week,\n",
        "                                patches_dates=patches_dates,\n",
        "                                main_function_type=main_function_type,\n",
        "                                chain_functions_type=chains_functions_type,\n",
        "                                main_function_initial_weights=main_function_weights,\n",
        "                                chain_functions_initial_weights=chains_functions_weights,\n",
        "                                week_function_initial_weights=week_function_weights)\n",
        "    y_modeled_with_oscillations = model.forward(x)\n",
        "    y_modeled_with_oscillations = torch.clamp(y_modeled_with_oscillations, 0, 1)\n",
        "\n",
        "    y_modeled_chains = []\n",
        "    for i, chain in enumerate(model.chain_functions):\n",
        "        chain_result = (x>=model.patches_dates[i]) * chain.forward(x)\n",
        "        y_modeled_chains.append(chain_result)\n",
        "\n",
        "    # Add noise to data using binomial model of returned users\n",
        "    sample_size = torch.rand_like(y_modeled_with_oscillations) * daily_installs_sigma + daily_installs_mean\n",
        "    sigma = torch.sqrt(-y_modeled_with_oscillations * (y_modeled_with_oscillations - 1) / sample_size)\n",
        "\n",
        "    y_modeled_final = torch.normal(mean=y_modeled_with_oscillations, std=sigma)\n",
        "\n",
        "    # Generate random indices for data wich don't have anomaly\n",
        "    probability_of_anomaly = 0.3\n",
        "    choosen = np.random.choice(a=[True, False], size=(total_days),\n",
        "                               p=[probability_of_anomaly, 1 - probability_of_anomaly])\n",
        "    bad_days = [i for i, e in enumerate(choosen) if e != 0]\n",
        "    #todo: modify retention at abnormal days\n",
        "\n",
        "    return x, sample_size, y_modeled_final, y_modeled_trend, y_modeled_with_oscillations, patches_dates, bad_days, week_function_weights, y_modeled_chains, model\n",
        "\n",
        "def plot_generated_retention_dataset(x_modeled,\n",
        "                                     y_modeled_final,\n",
        "                                     y_modeled_trend = None,\n",
        "                                     y_modeled_with_oscillations = None,\n",
        "                                     y_modeled_chains=None):\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    if y_modeled_chains is not None:\n",
        "        for i, chain in enumerate(y_modeled_chains):\n",
        "            plt.plot(x_modeled, chain.detach().numpy(), color='Grey', label=\"chain {0}\".format(i), marker='.', linestyle='')\n",
        "\n",
        "    if y_modeled_with_oscillations is not None:\n",
        "        plt.plot(x_modeled, y_modeled_with_oscillations.detach().numpy(), color='Green', label=\"y_modeled_with_oscillations\")\n",
        "\n",
        "    plt.plot(x_modeled, y_modeled_final.detach().numpy(), color='Blue', label=\"Train data\")\n",
        "\n",
        "    if y_modeled_trend is not None:\n",
        "        plt.plot(x_modeled, y_modeled_trend.detach().numpy(), color='Red', label=\"y_modeled_decreasing\", linewidth=3)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.05, 0.95), loc=2, borderaxespad=0., fontsize=12)\n",
        "    plt.title(\"Train data\", fontsize=12)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#test\n",
        "dates, installs, retention, retention_mean, retention_oscillated,\\\n",
        "    patches_dates, bad_days, week_weights, y_modeled_chains, generator_model = generate_retention_dataset_2(\n",
        "                        160,    #total_days\n",
        "                        2,      #first_day_of_week\n",
        "                        [30,60,90,120,150], #patches_dates\n",
        "                        '4',    #main_function_type\n",
        "                        '0',    #chains_functions_type\n",
        "                        [0.5,0.4,0.05],   #main_function_weights\n",
        "                        [0.01, 0.02, 0.02, 0.03, 0.04], #chains_functions_weights\n",
        "                        [1,1,1,1,1.05,1.05,0.9],    #week_function_weights\n",
        "                        1000,   #daily_installs_mean\n",
        "                        200)    #daily_installs_sigma\n",
        "#generator_model.print_summary(True)\n",
        "#plot_generated_retention_dataset(dates, retention, retention_mean, retention_oscillated)\n",
        "#plot_generated_retention_dataset(dates, retention, None, None)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RhNI8sig2sP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User initerface\n",
        "\n",
        "#%pip install -q ipywidgets\n",
        "\n",
        "date_of_release = None\n",
        "first_day_of_week = 0\n",
        "dates = None\n",
        "installs = None\n",
        "retention = None\n",
        "retention_mean = None\n",
        "retention_oscillated = None\n",
        "patches_dates = None\n",
        "bad_days = None\n",
        "week_weights = None\n",
        "\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "import ipywidgets as widgets\n",
        "import datetime\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "#Define butons\n",
        "data_upload_button = widgets.FileUpload(\n",
        "    multiple=False,\n",
        "    button_style='info')\n",
        "\n",
        "data_save_button = widgets.Button(\n",
        "    description='Save current train data',\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Save dataset',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "generator_start_button = widgets.Button(\n",
        "    description='Generate dataset',\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Generate dataset',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "#Define generators widgets\n",
        "generator_start_date_picker = widgets.DatePicker(value=datetime.date.today())\n",
        "generator_x_points_text_input = widgets.IntText(value='160')\n",
        "generator_patches_dates_text_input = widgets.Textarea(value='0, 60, 90, 150')\n",
        "generator_main_function_dropdown = widgets.Dropdown(\n",
        "    options=[name for name, _, _ in ApproximatorsFactory.main_functions],\n",
        "    value=ApproximatorsFactory.main_functions[3][0])\n",
        "generator_main_function_weights_text_input = widgets.Textarea(value='0.4, 0.08, 20')\n",
        "generator_chains_function_dropdown = widgets.Dropdown(\n",
        "    options=[name for name, _, _ in ApproximatorsFactory.chain_functions],\n",
        "    value=ApproximatorsFactory.chain_functions[0][0])\n",
        "generator_chains_function_weights_text_input = widgets.Textarea(value='0.01, 0.02, 0.03')\n",
        "generator_week_weights_text_input = widgets.Textarea(value='1,1,1,1,1.05,1.05,0.9')\n",
        "generator_daily_installs_mean_text_input = widgets.IntText(value='1000')\n",
        "generator_daily_installs_sigma_text_input = widgets.IntText(value='200')\n",
        "\n",
        "##Define approximators widgets\n",
        "approximator_main_function_dropdown = widgets.Dropdown(\n",
        "    options=[name for name, _, _ in ApproximatorsFactory.main_functions],\n",
        "    value=ApproximatorsFactory.main_functions[4][0])\n",
        "\n",
        "approximator_chain_function_dropdown = widgets.Dropdown(\n",
        "    options=[name for name, _, _ in ApproximatorsFactory.chain_functions],\n",
        "    value=ApproximatorsFactory.chain_functions[0][0])\n",
        "\n",
        "approximator_connector_dropdown = widgets.Dropdown(\n",
        "    options=[name for name, _, _ in ApproximatorsFactory.connectors])\n",
        "\n",
        "approximator_patches_dates_text_input = widgets.Textarea(\n",
        "    value='', layout=Layout(width='50%'))\n",
        "\n",
        "approximator_bad_dates_text_input = widgets.Textarea(\n",
        "    value='', layout=Layout(width='50%'))\n",
        "\n",
        "approximator_week_weights_text_input = widgets.Textarea(\n",
        "    value='1, 1, 1, 1, 1, 1, 1', layout=Layout(width='50%'))\n",
        "\n",
        "approximator_exclude_bad_dates_checkbox = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description = 'Exlude bad dates from training set',\n",
        "    layout=Layout(width='50%'))\n",
        "\n",
        "approximator_exclude_patch_dates_checkbox = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description = 'Exlude patch dates from training set',\n",
        "    layout=Layout(width='50%'))\n",
        "\n",
        "\n",
        "#Event handlers\n",
        "\n",
        "def check_decreaser_weights(x):\n",
        "\n",
        "    patch_dates_defined, generator_patches_dates, _ = check_dates(generator_patches_dates_text_input.value)\n",
        "\n",
        "    if not patch_dates_defined:\n",
        "        return False, [], 'Error! The dates of patches don''t defined'\n",
        "\n",
        "    if generator_patches_dates==[] and x.strip() == '':\n",
        "        return True, [], 'OK'\n",
        "\n",
        "    string_array = x.split(\",\")\n",
        "    try:\n",
        "        float_array = [float(item_value) for item_value in string_array]\n",
        "        if len(float_array) != len(generator_patches_dates)-1:\n",
        "            return False, float_array, 'Error! You should type exactly {0} float numbers'.format(len(generator_patches_dates)-1)\n",
        "        return True, float_array, 'OK'\n",
        "    except ValueError:        return False, [], 'Error! Can''t convert data to float array'\n",
        "\n",
        "def check_main_decreaser_weights(x):\n",
        "\n",
        "    len_main_decreaser_weights = len(ApproximatorsFactory.get_main_function_weights_number(generator_main_function_dropdown.value))\n",
        "\n",
        "    #val = generator_main_decreaser_type_dropdown.value\n",
        "\n",
        "    string_array = x.split(\",\")\n",
        "    try:\n",
        "        float_array = [float(item_value) for item_value in string_array]\n",
        "        if len(float_array) != len_main_decreaser_weights:\n",
        "            return False, float_array, 'Error! You should type exactly {0} float numbers'.format(len_main_decreaser_weights)\n",
        "        return True, float_array, 'OK'\n",
        "    except ValueError:\n",
        "        return False, [], 'Error! Can''t convert data to float array'\n",
        "\n",
        "def check_oscillator_weights(x):\n",
        "    string_array = x.split(\",\")\n",
        "    try:\n",
        "        float_array = [float(item_value) for item_value in string_array]\n",
        "        if len(float_array) != 7:\n",
        "            return False, float_array, 'Error! You should type exactly 7 float numbers'\n",
        "        return True, float_array, 'OK'\n",
        "    except ValueError:\n",
        "        return False, [], 'Error! Can''t convert data to float array'\n",
        "\n",
        "def check_dates(x):\n",
        "\n",
        "    if x.strip() =='':\n",
        "        return True, [], 'OK'\n",
        "\n",
        "    string_array = x.split(\",\")\n",
        "\n",
        "    try:\n",
        "        int_array = [int(item_value) for item_value in string_array]\n",
        "        int_array.sort()\n",
        "        if int_array[0]!=0:\n",
        "            int_array = [0]+int_array\n",
        "        for item_value in int_array:\n",
        "            if item_value < 0:\n",
        "                return False, [], 'Error! All the values must be >=0'\n",
        "            #todo: add 0 patch if it does not exist\n",
        "        return True, int_array, 'OK'\n",
        "    except ValueError:\n",
        "        return False, [], 'Error! Can''t convert data to int array'\n",
        "\n",
        "def check_decreaser_weights_and_print_result(x):\n",
        "    b, lst, err = check_decreaser_weights(x)\n",
        "    print(err)\n",
        "    print('{0} values found'.format(len(lst)))\n",
        "    return b\n",
        "\n",
        "def check_main_decreaser_weights_and_print_result(x):\n",
        "    b, lst, err = check_main_decreaser_weights(x)\n",
        "    print(err)\n",
        "    print('{0} values found'.format(len(lst)))\n",
        "    return b\n",
        "\n",
        "def check_oscillator_weights_and_print_result(x):\n",
        "    b, lst, err = check_oscillator_weights(x)\n",
        "    print(err)\n",
        "    print('{0} values found'.format(len(lst)))\n",
        "    return b\n",
        "\n",
        "def check_dates_and_print_result(x):\n",
        "    b, lst, err = check_dates(x)\n",
        "    print(err)\n",
        "    print('{0} values found'.format(len(lst)))\n",
        "    return b\n",
        "\n",
        "def on_generate_button_click(x):\n",
        "    global dates\n",
        "    global installs\n",
        "    global retention\n",
        "    global retention_mean\n",
        "    global retention_oscillated\n",
        "    global patches_dates\n",
        "    global bad_days\n",
        "    global week_weights\n",
        "    global first_day_of_week\n",
        "    global date_of_release\n",
        "\n",
        "    generator_main_decreaser_type = generator_main_function_dropdown.value\n",
        "    generator_decreasers_type = generator_chains_function_dropdown.value\n",
        "    generator_patches_dates_OK, generator_patches_dates, _ = check_dates(generator_patches_dates_text_input.value)\n",
        "    generator_main_decreaser_weights_ok, generator_main_decreaser_weights, _ = check_main_decreaser_weights(generator_main_function_weights_text_input.value)\n",
        "    generator_decreasers_weights_ok, generator_decreasers_weights, _ = check_decreaser_weights(generator_chains_function_weights_text_input.value)\n",
        "    generator_oscillator_weights_ok, generator_oscillator_weights, _ = check_oscillator_weights(generator_week_weights_text_input.value)\n",
        "\n",
        "    selected_date = generator_start_date_picker.value\n",
        "    try:\n",
        "        local_first_day_of_week = datetime.datetime.strptime(str(selected_date), '%Y-%m-%d').weekday()\n",
        "    except ValueError:\n",
        "        print(\"Erro! Select correct date\")\n",
        "        return\n",
        "\n",
        "    if not (generator_patches_dates_OK and\n",
        "            generator_main_decreaser_weights_ok and\n",
        "            generator_decreasers_weights_ok and\n",
        "            generator_oscillator_weights_ok):\n",
        "        print(\"Error! Input parameters are incorrect : patches dates {0}, main weights {1}, chain weights {2}, weeks weights {3}\".\n",
        "              format(generator_patches_dates_OK,\n",
        "                     generator_main_decreaser_weights_ok,\n",
        "                     generator_decreasers_weights_ok,\n",
        "                     generator_oscillator_weights_ok))\n",
        "        return\n",
        "\n",
        "    dates, installs, retention, retention_mean, retention_oscillated,\\\n",
        "        patches_dates, bad_days, week_weights, y_modeled_chains, generator_model = generate_retention_dataset_2(\n",
        "                            generator_x_points_text_input.value,\n",
        "                            local_first_day_of_week,\n",
        "                            generator_patches_dates,\n",
        "                            generator_main_decreaser_type,\n",
        "                            generator_decreasers_type,\n",
        "                            generator_main_decreaser_weights,\n",
        "                            generator_decreasers_weights,\n",
        "                            generator_oscillator_weights,\n",
        "                            generator_daily_installs_mean_text_input.value,\n",
        "                            generator_daily_installs_sigma_text_input.value)\n",
        "    first_day_of_week = local_first_day_of_week\n",
        "    date_of_release = selected_date\n",
        "\n",
        "    generator_model.print_summary()\n",
        "\n",
        "    approximator_patches_dates_text_input.value = \",\".join(str(x) for x in patches_dates)\n",
        "    approximator_bad_dates_text_input.value = \",\".join(str(x) for x in bad_days)\n",
        "    approximator_week_weights_text_input.value = \",\".join(str(x) for x in week_weights)\n",
        "\n",
        "    output.clear_output()\n",
        "\n",
        "    with output:\n",
        "        plot_generated_retention_dataset(dates, retention, retention_mean, retention_oscillated, None)\n",
        "\n",
        "def on_save_button_click(x):\n",
        "    global dates\n",
        "    global install\n",
        "    global retention\n",
        "    global retention_mean\n",
        "\n",
        "    if dates is not None and installs is not None and retention is not None:\n",
        "        save_retention_data_to_local_csv(dates.cpu(), installs.cpu(), retention.cpu(), retention_mean, date_of_release = date_of_release)\n",
        "\n",
        "def on_upload_change(change):\n",
        "\n",
        "    filename = list(change['new'].keys())[0]\n",
        "    content = change['new'][filename]['content']\n",
        "\n",
        "    global dates\n",
        "    global installs\n",
        "    global retention\n",
        "    global retention_mean\n",
        "    global first_day_of_week\n",
        "    global date_of_release\n",
        "\n",
        "    dates, installs, retention, retention_mean, date_of_release, df = load_retention_from_local_csv(io.StringIO(content.decode()))\n",
        "\n",
        "    if df is not None:\n",
        "        first_day_of_week = date_of_release.weekday()\n",
        "        output.clear_output()\n",
        "        retention_oscillated = None\n",
        "        with output:\n",
        "            print('Uploading is usccessful')\n",
        "            plot_generated_retention_dataset(dates, retention, retention_mean, retention_oscillated)\n",
        "    else:\n",
        "        with output:\n",
        "            display('Uploading error')\n",
        "\n",
        "generator_start_button.on_click(on_generate_button_click)\n",
        "data_save_button.on_click(on_save_button_click)\n",
        "data_upload_button.observe(on_upload_change, names='value')\n",
        "\n",
        "#Display all the widgets\n",
        "\n",
        "#Compose generator widgets\n",
        "generator_settings = widgets.VBox([\n",
        "    widgets.HTML(\"<b>Generator</b>\"),\n",
        "    widgets.HTML(\"Fill all the parameters bellow and then press the button 'Generate dataset'\"),\n",
        "    widgets.HBox([generator_start_date_picker,\n",
        "                  widgets.Label('Select the date of release')]),\n",
        "    widgets.HBox([generator_x_points_text_input,\n",
        "                  widgets.Label('Total quantity of days, int')]),\n",
        "    widgets.HBox([generator_patches_dates_text_input,\n",
        "                  widgets.Label('List of patches, integers separated by commas, excluding release patch'),\n",
        "                  widgets.interactive_output(check_dates_and_print_result, {'x': generator_patches_dates_text_input})]),\n",
        "    widgets.HBox([generator_main_function_dropdown,\n",
        "                  widgets.Label('Type of the main trend')]),\n",
        "    widgets.HBox([generator_chains_function_dropdown,\n",
        "                  widgets.Label('Type of approximators of the patches')]),\n",
        "    widgets.HBox([generator_main_function_weights_text_input,\n",
        "                  widgets.Label('Weights of the main trend'),\n",
        "                  widgets.interactive_output(check_main_decreaser_weights_and_print_result, {'x': generator_main_function_weights_text_input})]),\n",
        "    widgets.HBox([generator_chains_function_weights_text_input,\n",
        "                  widgets.Label('Weights of approximators of the patches'),\n",
        "                  widgets.interactive_output(check_decreaser_weights_and_print_result, {'x': generator_chains_function_weights_text_input})]),\n",
        "    widgets.HBox([generator_daily_installs_mean_text_input,\n",
        "                  widgets.Label('Mean value of installs every day, int')]),\n",
        "    widgets.HBox([generator_daily_installs_sigma_text_input,\n",
        "                  widgets.Label('Standard deviation of installs every day, int')]),\n",
        "    widgets.HBox([generator_week_weights_text_input,\n",
        "                  widgets.Label('Weights of days of week, 7 floats from Mon to Sun'),\n",
        "                  widgets.interactive_output(check_oscillator_weights_and_print_result, {'x': generator_week_weights_text_input})]),\n",
        "    #widgets.HBox([oscillator_weights, widgets.Label('Enter the weight of every day of week. 7 float numbers from Monday to Sunday')])#,\n",
        "    #widgets.HBox([dataGenerateButton, widgets.Label('Autogenerate dataset and all the parameters bellow')])\n",
        "    widgets.HBox([generator_start_button,\n",
        "                      widgets.Label('Generate dataset, display it and and fill the parameters of approximator on the right')])\n",
        "    ],\n",
        "    layout=widgets.Layout(border='solid 2px gray', padding='10px', width = '50%'))\n",
        "\n",
        "\n",
        "#Compose approximator widgets\n",
        "approximator_settings = widgets.VBox([\n",
        "    widgets.HTML(\"<b>Approximator</b>\"),\n",
        "    widgets.HTML(\"Upload or generate train data, then fill all the parameters <br>and then launch the block bellow 'Create the regression model and train it'\"),\n",
        "    widgets.HBox([data_upload_button,\n",
        "                      widgets.Label('Upload source retention data from local csv-file with 3 columns: date:int>=0, installs:int>0, retention:float[0,1]')]),\n",
        "    widgets.HBox([approximator_patches_dates_text_input,\n",
        "                  widgets.Label('List of patches, integers separated by commas, excluding release patch'),\n",
        "                  widgets.interactive_output(check_dates_and_print_result, {'x': approximator_patches_dates_text_input})]),\n",
        "    widgets.HBox([approximator_main_function_dropdown,\n",
        "                  widgets.Label('Type of the main trend')]),\n",
        "    widgets.HBox([approximator_chain_function_dropdown,\n",
        "                  widgets.Label('Type of approximators of the patches')]),\n",
        "    widgets.HBox([approximator_connector_dropdown,\n",
        "                  widgets.Label('Type of connection function')]),\n",
        "    widgets.HBox([approximator_week_weights_text_input,\n",
        "                  widgets.Label('Weights of days of week, 7 floats from Mon to Sun'),\n",
        "                  widgets.interactive_output(check_oscillator_weights_and_print_result,\n",
        "                                {'x': approximator_week_weights_text_input})]),\n",
        "    widgets.HBox([approximator_bad_dates_text_input,\n",
        "                  widgets.Label('List of bad days, integers separeted by commas'),\n",
        "                  widgets.interactive_output(check_dates_and_print_result, {'x': approximator_bad_dates_text_input})]),\n",
        "    approximator_exclude_bad_dates_checkbox,\n",
        "    approximator_exclude_patch_dates_checkbox\n",
        "    ],\n",
        "    layout=widgets.Layout(border='solid 2px gray', padding='10px', width = '50%'))\n",
        "\n",
        "all_settings = widgets.HBox([\n",
        "    generator_settings,\n",
        "    approximator_settings])\n",
        "\n",
        "display(all_settings)\n",
        "display(output)\n",
        "display(widgets.HBox([data_save_button,\n",
        "                      widgets.Label('Save dataset to local file')]))"
      ],
      "metadata": {
        "id": "9B5ue8bf1ehr",
        "execution": {
          "iopub.status.busy": "2023-04-25T13:55:08.338016Z",
          "iopub.execute_input": "2023-04-25T13:55:08.338431Z",
          "iopub.status.idle": "2023-04-25T13:55:08.816956Z",
          "shell.execute_reply.started": "2023-04-25T13:55:08.338399Z",
          "shell.execute_reply": "2023-04-25T13:55:08.815651Z"
        },
        "trusted": true,
        "cellView": "form",
        "ExecuteTime": {
          "end_time": "2023-05-01T19:10:09.205540400Z",
          "start_time": "2023-05-01T19:10:08.296393900Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the regression model and train it\n",
        "\n",
        "#import Retention_approximators_1d from Retention_approximators_1d.py\n",
        "#from Retention_approximators_1d.py import ComplexApproximatorNew\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration of training strategy\n",
        "# Every row is a one iteration of training, containing parameters:\n",
        "# epochs, trend_function_trainable, week_function_trainable, learning_rate\n",
        "# If we have a few of data it's recommended to train only trend but not a weeks function\n",
        "training_strategy = [\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('LBFGS',  5, True, False, 0.01),\n",
        "    ('LBFGS',  5, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.01),\n",
        "    ('Adam', 500, True, False, 0.001),\n",
        "    ('Adam', 500, True, True, 0.001),\n",
        "    ('Adam', 500, True, True, 0.001)]\n",
        "\n",
        "loss_function = 'custom'    #possible values: 'mse'- standard mse, 'custom' - weighted least squares with weeks regularizer\n",
        "regualizer_lambda = 100     #weight of regularized function\n",
        "number_of_sigmas_for_plotting = 3   #confidence interval width\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Load the settings from the form above\n",
        "main_function_type=approximator_main_function_dropdown.value\n",
        "chain_function_type=approximator_chain_function_dropdown.value\n",
        "connector_type=approximator_connector_dropdown.value\n",
        "_, patches_dates, _ = check_dates(approximator_patches_dates_text_input.value)\n",
        "_, bad_dates, _ = check_dates(approximator_bad_dates_text_input.value)\n",
        "_, oscillator_initial_weights, _ = check_oscillator_weights(approximator_week_weights_text_input.value)\n",
        "\n",
        "patches_dates = [*set(patches_dates)]\n",
        "patches_dates.sort()\n",
        "\n",
        "if approximator_exclude_bad_dates_checkbox.value:\n",
        "    bad_dates = [*set(bad_dates)]\n",
        "else:\n",
        "    bad_dates=[]\n",
        "\n",
        "if approximator_exclude_patch_dates_checkbox.value:\n",
        "    bad_dates = [*set(bad_dates).union(set(patches_dates))]\n",
        "\n",
        "if dates!=None:\n",
        "    good_days_indices = [index for index in range(len(dates)) if dates[index] not in bad_dates]\n",
        "else:\n",
        "    sys.exit(\"Training dataset is not found\")\n",
        "\n",
        "dates = dates.to(device=device)\n",
        "retention = retention.to(device=device)\n",
        "installs = installs.to(device=device)\n",
        "\n",
        "dates_excluding_bad = dates[good_days_indices].to(device=device).detach()\n",
        "retention_excluding_bad = retention[good_days_indices].to(device=device).detach()\n",
        "installs_excluding_bad = installs[good_days_indices].to(device=device).detach()\n",
        "\n",
        "if retention_oscillated != None:\n",
        "    retention_oscillated_excluding_bad = retention_oscillated[good_days_indices].to(device=device).detach()\n",
        "\n",
        "model = ComplexApproximator(first_day_of_week,\n",
        "                            patches_dates=patches_dates,\n",
        "                            main_function_type=main_function_type,\n",
        "                            chain_functions_type=chain_function_type,\n",
        "                            main_function_initial_weights=[0.4, 0.08, 20],\n",
        "                            week_function_initial_weights=week_weights)\n",
        "\n",
        "model.init_weights_from_train_data(dates_excluding_bad, retention_excluding_bad)\n",
        "\n",
        "print(\"Initial weights\")\n",
        "model.print_summary()\n",
        "\n",
        "# sys.exit()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "#Training\n",
        "\n",
        "model.train()\n",
        "\n",
        "for i in range(len(training_strategy)):\n",
        "\n",
        "    print(\"\\nIteration \", i+1)\n",
        "\n",
        "    # Apply configuration of training\n",
        "    optimizer_name, epochs, trend_function_trainable, week_function_trainable, learning_rate = training_strategy[i]\n",
        "\n",
        "    if optimizer_name == 'LBFGS':\n",
        "        optimizer = torch.optim.LBFGS(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Disabling weights if required\n",
        "    model.week_function.requires_grad_(week_function_trainable)\n",
        "    for dec_chain in model.chain_functions:\n",
        "        dec_chain.requires_grad_(trend_function_trainable)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            retention_predicted = model(dates_excluding_bad)\n",
        "            if loss_function == \"custom\":\n",
        "                loss = custom_mse_loss(retention_predicted,\n",
        "                                    retention_excluding_bad,\n",
        "                                    installs_excluding_bad,\n",
        "                                    model.regularize,\n",
        "                                    regualizer_lambda)\n",
        "            else:\n",
        "                loss = torch.nn.functional.mse_loss(retention_predicted, retention_excluding_bad)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "#\n",
        "        optimizer.step(closure)\n",
        "        loss = closure().item()\n",
        "\n",
        "    # Visualize the results of training\n",
        "    retention_predicted_for_plot = model.forward(dates)\n",
        "    retention_predicted_avg = model.forward_trend_function(dates)\n",
        "    retention_predicted_osc = model.forward_week_function(dates)\n",
        "\n",
        "    sigma_retention = torch.sqrt(-retention * (retention-1)/installs)\n",
        "    retention_min = retention / retention_predicted_osc - number_of_sigmas_for_plotting * sigma_retention\n",
        "    retention_max = retention / retention_predicted_osc + number_of_sigmas_for_plotting * sigma_retention\n",
        "\n",
        "    print('Results of iteration')\n",
        "    print('Loss = ', loss)\n",
        "    if retention_oscillated != None:\n",
        "        loss_original = custom_mse_loss(retention_oscillated_excluding_bad,\n",
        "                                    retention_excluding_bad,\n",
        "                                    installs_excluding_bad,\n",
        "                                    model.regularize,\n",
        "                                    regualizer_lambda)\n",
        "        print('Ideal loss = ', loss_original.item())\n",
        "    model.print_summary()\n",
        "\n",
        "    plt.figure(figsize=(30, 12))\n",
        "\n",
        "    plt.fill_between(dates.cpu().detach().numpy(),\n",
        "                     retention_min.cpu().detach().numpy(),\n",
        "                     retention_max.cpu().detach().numpy(),\n",
        "                     color='#000044',   label=\"Source confidence interval\", linestyle='dotted')\n",
        "\n",
        "    retention_predicted_trend = model.forward_trend_function(dates_excluding_bad)\n",
        "    retention_estimated_min, retention_estimated_max = \\\n",
        "        evaluate_ideal_confidence_interval(dates_excluding_bad.cpu().detach(),\n",
        "                                           retention_predicted_trend.cpu().detach(),\n",
        "                                           installs_excluding_bad.cpu().detach(),\n",
        "                                           patches_dates,\n",
        "                                           number_of_sigmas_for_plotting,\n",
        "                                           dates,\n",
        "                                           retention_predicted_avg.cpu().detach())\n",
        "\n",
        "    plt.fill_between(dates.cpu().detach().numpy(),\n",
        "                     retention_estimated_min.cpu().detach().numpy(),\n",
        "                     retention_estimated_max.cpu().detach().numpy(),\n",
        "                     color='#BBBBBB', label=\"Best confidence interval\", alpha=0.8)\n",
        "\n",
        "    if retention_oscillated != None and retention_oscillated.shape == dates.shape:\n",
        "        plt.plot(dates.cpu().detach().numpy(), retention_oscillated.cpu().detach().numpy(),  color='Green',  label=\"Source data without noise\")\n",
        "\n",
        "    plt.plot(dates.cpu().detach().numpy(), retention.cpu().detach().numpy(),        color='Blue',   label=\"Source data\")\n",
        "    plt.plot(dates_excluding_bad.cpu().detach().numpy(), retention_excluding_bad.cpu().detach().numpy(), color='Blue', label=\"Train data\", marker='o', linestyle='')\n",
        "\n",
        "    plt.plot(dates.cpu().detach().numpy(), retention_predicted_for_plot.cpu().detach().numpy(), color='Magenta', label=\"Predicted data\", linewidth=3)\n",
        "\n",
        "    if retention_mean != None:\n",
        "        plt.plot(dates.cpu().detach().numpy(), retention_mean.cpu().detach().numpy(),   color='Red',    label=\"Original trend\")\n",
        "\n",
        "    plt.plot(dates.cpu().detach().numpy(), retention_predicted_avg.cpu().detach().numpy(), color='Red', label=\"Predicted trend\", linewidth=5)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.05, 0.95), loc=2, borderaxespad=0., fontsize=17)\n",
        "    plt.title(\"Iteration {0} of {1}\".format(i+1, len(training_strategy)), fontsize=17)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OSj9XvUWQhX0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}